import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
df=pd.read_csv('dhakaqu.csv')
df
df.kurtosis().sort_values(ascending=False)
df.skew().sort_values(ascending=False)
df.describe()
plt.figure(figsize = (15,10))
sns.set(font_scale=1.7)
viz=sns.heatmap(df[['N60','PI','Depth(m)','qu']].corr(),annot=True,cmap="Spectral")
x=df.iloc[:,:-1]
y=df.iloc[:,-1]
x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.70,test_size=0.3,random_state=98)
ml=LinearRegression()
ml.fit(x_train,y_train)
ad=AdaBoostRegressor(n_estimators=100,learning_rate=1)
ad.fit(x_train,y_train)
rf=RandomForestRegressor()
X=rf.fit(x_train,y_train)
from yellowbrick.regressor import ResidualsPlot
plt.figure(figsize = (15,10))
sns.set(font_scale=1.5)
visualizer=ResidualsPlot(X)
visualizer.fit(x_train,y_train)
visualizer.score(x_test,y_test)
visualizer.poof()
y_pred_test=rf.predict(x_test)
y_pred_train=rf.predict(x_train)
np.abs(r2_score(y_train,y_pred_train))
np.abs(r2_score(y_test,y_pred_test))
np.sqrt(mean_squared_error(y_train,y_pred_train))
np.sqrt(mean_squared_error(y_test,y_pred_test))
mean_absolute_error(y_train,y_pred_train)
mean_absolute_error(y_test,y_pred_test)
